{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from Bio.Align import substitution_matrices\n",
    "import pyensembl\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.applications import ResNet101, NASNetLarge\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "import time\n",
    "from keras import backend as K\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_for_model_2_ds.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[data['target']==1]\n",
    "data_0 = data[data['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = data_0.sample(frac=len(data_1)/len(data_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_1.append(data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_csv('structures_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures['pair'] = structures['pair'].astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures['max_prob'] = structures['max_prob'].apply(lambda p: str(np.round(p, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_seq = []\n",
    "for ENST in pd.unique(structures['ENST']):\n",
    "    struc = structures[structures['ENST']==ENST]\n",
    "    struc = struc.sort_values(by=['ind'])\n",
    "    pair = ''.join(struc['pair'])\n",
    "    prob = ';'.join(struc['max_prob'])\n",
    "    struc_seq.append([ENST, pair, prob])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_seq = pd.DataFrame(struc_seq, columns=('ENST', 'pair', 'prob'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, struc_seq, on=['ENST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, data['target'], test_size=0.2, random_state=42, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_n = {'A':0, 'T':1, 'C':2, 'G':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "image1 = np.zeros((batch_size, 25, 4))\n",
    "image2 = np.zeros((batch_size, 10000, 6))\n",
    "target = np.zeros((batch_size, 1))\n",
    "for k in range(batch_size):\n",
    "    example = X_train.iloc[i]\n",
    "    \n",
    "    lncrna = example['lncrna_read']\n",
    "    mirna = example['mirna_read']\n",
    "    \n",
    "    pair = example['pair']\n",
    "    prob = example['prob'].split(';')\n",
    "    \n",
    "    change = {'A':'T', 'T':'A', 'C':'G', 'G':'C', '_':'_'}\n",
    "\n",
    "    mirna = mirna.replace('U', 'T')\n",
    "    mirna = mirna[::-1]\n",
    "    mirna = ''.join([change[i] for i in mirna])\n",
    "    lncrna = lncrna.replace('U', 'T')\n",
    "\n",
    "    if len(lncrna)<=10000:\n",
    "        for j in range(len(mirna)):\n",
    "            Nucl = dict_n[mirna[j]]\n",
    "            image1[k, j, Nucl] = 1\n",
    "\n",
    "        for j in range(len(lncrna)):\n",
    "            Nucl = dict_n[lncrna[j]]\n",
    "            image2[k, j, Nucl] = 1\n",
    "            image2[k, j, 4] = int(pair[j])\n",
    "            image2[k, j, 5] = float(prob[j])\n",
    "            \n",
    "            \n",
    "    target[k] = example['target']\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train(i=0, batch_size = batch_size):\n",
    "    while True:\n",
    "        image1 = np.zeros((batch_size, 25, 4))\n",
    "        image2 = np.zeros((batch_size, 10000, 4))\n",
    "        target = np.zeros((batch_size, 1))\n",
    "        for k in range(batch_size):\n",
    "            example = X_train.iloc[i]\n",
    "\n",
    "            lncrna = example['lncrna_read']\n",
    "            mirna = example['mirna_read']\n",
    "\n",
    "            pair = example['pair']\n",
    "            prob = example['prob'].split(';')\n",
    "\n",
    "            change = {'A':'T', 'T':'A', 'C':'G', 'G':'C', '_':'_'}\n",
    "\n",
    "            mirna = mirna.replace('U', 'T')\n",
    "            mirna = mirna[::-1]\n",
    "            mirna = ''.join([change[i] for i in mirna])\n",
    "            lncrna = lncrna.replace('U', 'T')\n",
    "\n",
    "            if len(lncrna)<=10000:\n",
    "                for j in range(len(mirna)):\n",
    "                    Nucl = dict_n[mirna[j]]\n",
    "                    image1[k, j, Nucl] = 1\n",
    "\n",
    "                for j in range(len(lncrna)):\n",
    "                    Nucl = dict_n[lncrna[j]]\n",
    "                    image2[k, j, Nucl] = 1\n",
    "#                     image2[k, j, 4] = int(pair[j])\n",
    "#                     image2[k, j, 5] = float(prob[j])\n",
    "\n",
    "\n",
    "            target[k] = example['target']\n",
    "            i += 1\n",
    "        if i>=len(X_train)-batch_size+1:\n",
    "            i = 0\n",
    "        yield  [image1, image2], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_test(i=0, batch_size = batch_size):\n",
    "    while True:\n",
    "        image1 = np.zeros((batch_size, 25, 4))\n",
    "        image2 = np.zeros((batch_size, 10000, 4))\n",
    "        target = np.zeros((batch_size, 1))\n",
    "        for k in range(batch_size):\n",
    "            example = X_test.iloc[i]\n",
    "\n",
    "            lncrna = example['lncrna_read']\n",
    "            mirna = example['mirna_read']\n",
    "\n",
    "            pair = example['pair']\n",
    "            prob = example['prob'].split(';')\n",
    "\n",
    "            change = {'A':'T', 'T':'A', 'C':'G', 'G':'C', '_':'_'}\n",
    "\n",
    "            mirna = mirna.replace('U', 'T')\n",
    "            mirna = mirna[::-1]\n",
    "            mirna = ''.join([change[i] for i in mirna])\n",
    "            lncrna = lncrna.replace('U', 'T')\n",
    "\n",
    "            if len(lncrna)<=10000:\n",
    "                for j in range(len(mirna)):\n",
    "                    Nucl = dict_n[mirna[j]]\n",
    "                    image1[k, j, Nucl] = 1\n",
    "\n",
    "                for j in range(len(lncrna)):\n",
    "                    Nucl = dict_n[lncrna[j]]\n",
    "                    image2[k, j, Nucl] = 1\n",
    "#                     image2[k, j, 4] = int(pair[j])\n",
    "#                     image2[k, j, 5] = float(prob[j])\n",
    "\n",
    "\n",
    "            target[k] = example['target']\n",
    "            i += 1\n",
    "        if i>=len(X_test)-batch_size+1:\n",
    "            i = 0\n",
    "        yield  [image1, image2], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.5\n",
    "tf.keras.backend.clear_session()\n",
    "input_x = Input(shape=(25, 4))\n",
    "x = layers.Conv1D(int(2048*k), (8), activation='relu')(input_x)\n",
    "x = layers.MaxPooling1D((2))(x)\n",
    "x = layers.Dropout(0.05)(x)\n",
    "# x = layers.LSTM(8, return_sequences=True)(x)\n",
    "# x = layers.Conv1D(1024, (4), activation='relu', padding='causal')(x)\n",
    "x = layers.Conv1D(int(1024*k), (4), activation='relu')(x)\n",
    "# x = layers.MaxPooling1D((2))(x)\n",
    "x = layers.Dropout(0.05)(x)\n",
    "x = layers.Conv1D(int(512*k), (4), activation='relu')(x)\n",
    "# x = layers.MaxPooling1D((2))(x)\n",
    "x = layers.Dropout(0.05)(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "input_y = Input(shape=(10000, 4))\n",
    "y = layers.Conv1D(int(2048*k), (8), activation='relu')(input_y)\n",
    "y = layers.MaxPooling1D((2))(y)\n",
    "y = layers.Dropout(0.05)(y)\n",
    "# y = layers.LSTM(8, return_sequences=True)(y)\n",
    "y = layers.Conv1D(int(1024*k), (4), activation='relu')(y)\n",
    "y = layers.MaxPooling1D((2))(y)\n",
    "y = layers.Dropout(0.05)(y)\n",
    "y = layers.Conv1D(int(512*k), (4), activation='relu')(y)\n",
    "y = layers.MaxPooling1D((2))(y)\n",
    "y = layers.Dropout(0.05)(y)\n",
    "y = layers.Flatten()(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "concatenated = layers.concatenate([x, y], axis=-1)\n",
    "out = layers.Dense(1, activation='sigmoid')(concatenated)\n",
    "model = Model([input_x, input_y], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-5), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = X_train.shape[0]//batch_size\n",
    "test_size = X_test.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list=[\n",
    "                keras.callbacks.EarlyStopping(monitor='val_acc', patience=1500),\n",
    "                keras.callbacks.ModelCheckpoint(filepath='best_model_2ds.h5', monitor='val_acc', \n",
    "                                                save_best_only=True, mode='max')\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "                generator_train(),\n",
    "                steps_per_epoch=train_size,\n",
    "                epochs=1000,\n",
    "                validation_data=generator_test(),\n",
    "                validation_steps=test_size,\n",
    "                callbacks=callbacks_list\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('best_model_2ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = []\n",
    "y_all = []\n",
    "k = 0\n",
    "for i in generator_test():\n",
    "    pred = model.predict(i[0])\n",
    "    y = i[1]\n",
    "    pred_all = pred_all + list(pred)\n",
    "    y_all = y_all + list(y)\n",
    "    k = k + 1\n",
    "    if k>test_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = np.array([i[0] for i in pred_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all2 = np.where(pred_all>0.9, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_all, pred_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_all, pred_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
